{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RecurrentNeuralNetwork(RNN).ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMIAt42Lp7hP9rmfP4InNQe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HasanALI313/Covnets/blob/main/RecurrentNeuralNetwork(RNN).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TW5tIAgHHan3",
        "outputId": "d0e64122-9e50-4e9c-e717-64e9f54aa5a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n",
            "17473536/17464789 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "from keras.datasets import imdb\n",
        "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sg83BIh2Imfl",
        "outputId": "76870a88-cadf-4c81-ee42-2b236b01d5d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1,\n",
              " 14,\n",
              " 22,\n",
              " 16,\n",
              " 43,\n",
              " 530,\n",
              " 973,\n",
              " 1622,\n",
              " 1385,\n",
              " 65,\n",
              " 458,\n",
              " 4468,\n",
              " 66,\n",
              " 3941,\n",
              " 4,\n",
              " 173,\n",
              " 36,\n",
              " 256,\n",
              " 5,\n",
              " 25,\n",
              " 100,\n",
              " 43,\n",
              " 838,\n",
              " 112,\n",
              " 50,\n",
              " 670,\n",
              " 2,\n",
              " 9,\n",
              " 35,\n",
              " 480,\n",
              " 284,\n",
              " 5,\n",
              " 150,\n",
              " 4,\n",
              " 172,\n",
              " 112,\n",
              " 167,\n",
              " 2,\n",
              " 336,\n",
              " 385,\n",
              " 39,\n",
              " 4,\n",
              " 172,\n",
              " 4536,\n",
              " 1111,\n",
              " 17,\n",
              " 546,\n",
              " 38,\n",
              " 13,\n",
              " 447,\n",
              " 4,\n",
              " 192,\n",
              " 50,\n",
              " 16,\n",
              " 6,\n",
              " 147,\n",
              " 2025,\n",
              " 19,\n",
              " 14,\n",
              " 22,\n",
              " 4,\n",
              " 1920,\n",
              " 4613,\n",
              " 469,\n",
              " 4,\n",
              " 22,\n",
              " 71,\n",
              " 87,\n",
              " 12,\n",
              " 16,\n",
              " 43,\n",
              " 530,\n",
              " 38,\n",
              " 76,\n",
              " 15,\n",
              " 13,\n",
              " 1247,\n",
              " 4,\n",
              " 22,\n",
              " 17,\n",
              " 515,\n",
              " 17,\n",
              " 12,\n",
              " 16,\n",
              " 626,\n",
              " 18,\n",
              " 2,\n",
              " 5,\n",
              " 62,\n",
              " 386,\n",
              " 12,\n",
              " 8,\n",
              " 316,\n",
              " 8,\n",
              " 106,\n",
              " 5,\n",
              " 4,\n",
              " 2223,\n",
              " 5244,\n",
              " 16,\n",
              " 480,\n",
              " 66,\n",
              " 3785,\n",
              " 33,\n",
              " 4,\n",
              " 130,\n",
              " 12,\n",
              " 16,\n",
              " 38,\n",
              " 619,\n",
              " 5,\n",
              " 25,\n",
              " 124,\n",
              " 51,\n",
              " 36,\n",
              " 135,\n",
              " 48,\n",
              " 25,\n",
              " 1415,\n",
              " 33,\n",
              " 6,\n",
              " 22,\n",
              " 12,\n",
              " 215,\n",
              " 28,\n",
              " 77,\n",
              " 52,\n",
              " 5,\n",
              " 14,\n",
              " 407,\n",
              " 16,\n",
              " 82,\n",
              " 2,\n",
              " 8,\n",
              " 4,\n",
              " 107,\n",
              " 117,\n",
              " 5952,\n",
              " 15,\n",
              " 256,\n",
              " 4,\n",
              " 2,\n",
              " 7,\n",
              " 3766,\n",
              " 5,\n",
              " 723,\n",
              " 36,\n",
              " 71,\n",
              " 43,\n",
              " 530,\n",
              " 476,\n",
              " 26,\n",
              " 400,\n",
              " 317,\n",
              " 46,\n",
              " 7,\n",
              " 4,\n",
              " 2,\n",
              " 1029,\n",
              " 13,\n",
              " 104,\n",
              " 88,\n",
              " 4,\n",
              " 381,\n",
              " 15,\n",
              " 297,\n",
              " 98,\n",
              " 32,\n",
              " 2071,\n",
              " 56,\n",
              " 26,\n",
              " 141,\n",
              " 6,\n",
              " 194,\n",
              " 7486,\n",
              " 18,\n",
              " 4,\n",
              " 226,\n",
              " 22,\n",
              " 21,\n",
              " 134,\n",
              " 476,\n",
              " 26,\n",
              " 480,\n",
              " 5,\n",
              " 144,\n",
              " 30,\n",
              " 5535,\n",
              " 18,\n",
              " 51,\n",
              " 36,\n",
              " 28,\n",
              " 224,\n",
              " 92,\n",
              " 25,\n",
              " 104,\n",
              " 4,\n",
              " 226,\n",
              " 65,\n",
              " 16,\n",
              " 38,\n",
              " 1334,\n",
              " 88,\n",
              " 12,\n",
              " 16,\n",
              " 283,\n",
              " 5,\n",
              " 16,\n",
              " 4472,\n",
              " 113,\n",
              " 103,\n",
              " 32,\n",
              " 15,\n",
              " 16,\n",
              " 5345,\n",
              " 19,\n",
              " 178,\n",
              " 32]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels[0:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iNHLNADtIxIV",
        "outputId": "b246a6bf-94c4-4a3b-d498-21304f6e6854"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def vectorize_sequences(sequences, dimension=10000):\n",
        "    #Creates an all-zero matrix\n",
        "    results = np.zeros((len(sequences), dimension))\n",
        "    #Set approperiate indices of the tensor result to 1s\n",
        "    for i, sequence in enumerate(sequences):\n",
        "        results[i, sequence] = 1.\n",
        "    return results\n",
        "\n",
        "#Turn Python lists into NumPy tensors\n",
        "x_train = vectorize_sequences(train_data)\n",
        "x_test = vectorize_sequences(test_data)\n",
        "\n",
        "# print out parts of x_train to see what is in it...\n",
        "print(x_train[:9])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FzoFGSK3I0eE",
        "outputId": "5d0931d2-5238-4bc1-a81d-da908adfc18e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 1. 1. ... 0. 0. 0.]\n",
            " [0. 1. 1. ... 0. 0. 0.]\n",
            " [0. 1. 1. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 1. 1. ... 0. 0. 0.]\n",
            " [0. 1. 1. ... 0. 0. 0.]\n",
            " [0. 1. 1. ... 0. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = np.asarray(train_labels).astype('float32')\n",
        "y_test = np.asarray(test_labels).astype('float32')\n",
        "\n",
        "# print out parts of y_train to see what is in it...\n",
        "print(y_train[:9])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WFr74uW7I2fs",
        "outputId": "6b392eef-6717-44ea-bc06-c176ec51b9e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1. 0. 0. 1. 0. 0. 1. 0. 1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
        "model.add(layers.Dense(16, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='binary_crossentropy',\n",
        "             metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "rQcKb_t-I4d0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Setting aside a validation set\n",
        "x_val = x_train[:10000]\n",
        "partial_x_train = x_train[10000:]\n",
        "\n",
        "y_val = y_train[:10000]\n",
        "partial_y_train = y_train[10000:]\n",
        "\n",
        "#Training the model\n",
        "model.fit(partial_x_train,\n",
        "          partial_y_train,\n",
        "          epochs=20,\n",
        "          batch_size=512,\n",
        "          validation_data=(x_val, y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3qUWdp6pI6WM",
        "outputId": "a7d2947f-319d-4b63-a293-9116529dcf4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "30/30 [==============================] - 4s 64ms/step - loss: 0.4879 - accuracy: 0.7911 - val_loss: 0.4348 - val_accuracy: 0.8093\n",
            "Epoch 2/20\n",
            "30/30 [==============================] - 2s 57ms/step - loss: 0.2892 - accuracy: 0.9025 - val_loss: 0.3133 - val_accuracy: 0.8765\n",
            "Epoch 3/20\n",
            "30/30 [==============================] - 2s 60ms/step - loss: 0.2135 - accuracy: 0.9283 - val_loss: 0.2729 - val_accuracy: 0.8909\n",
            "Epoch 4/20\n",
            "30/30 [==============================] - 2s 54ms/step - loss: 0.1645 - accuracy: 0.9473 - val_loss: 0.2887 - val_accuracy: 0.8827\n",
            "Epoch 5/20\n",
            "30/30 [==============================] - 1s 42ms/step - loss: 0.1353 - accuracy: 0.9541 - val_loss: 0.3009 - val_accuracy: 0.8814\n",
            "Epoch 6/20\n",
            "30/30 [==============================] - 1s 37ms/step - loss: 0.1130 - accuracy: 0.9630 - val_loss: 0.3078 - val_accuracy: 0.8807\n",
            "Epoch 7/20\n",
            "30/30 [==============================] - 1s 36ms/step - loss: 0.0893 - accuracy: 0.9742 - val_loss: 0.3223 - val_accuracy: 0.8808\n",
            "Epoch 8/20\n",
            "30/30 [==============================] - 1s 36ms/step - loss: 0.0747 - accuracy: 0.9781 - val_loss: 0.3452 - val_accuracy: 0.8785\n",
            "Epoch 9/20\n",
            "30/30 [==============================] - 1s 36ms/step - loss: 0.0625 - accuracy: 0.9830 - val_loss: 0.3834 - val_accuracy: 0.8732\n",
            "Epoch 10/20\n",
            "30/30 [==============================] - 1s 37ms/step - loss: 0.0503 - accuracy: 0.9875 - val_loss: 0.4450 - val_accuracy: 0.8680\n",
            "Epoch 11/20\n",
            "30/30 [==============================] - 1s 37ms/step - loss: 0.0439 - accuracy: 0.9883 - val_loss: 0.4388 - val_accuracy: 0.8691\n",
            "Epoch 12/20\n",
            "30/30 [==============================] - 1s 38ms/step - loss: 0.0326 - accuracy: 0.9930 - val_loss: 0.4620 - val_accuracy: 0.8734\n",
            "Epoch 13/20\n",
            "30/30 [==============================] - 1s 37ms/step - loss: 0.0273 - accuracy: 0.9951 - val_loss: 0.4894 - val_accuracy: 0.8709\n",
            "Epoch 14/20\n",
            "30/30 [==============================] - 1s 40ms/step - loss: 0.0215 - accuracy: 0.9967 - val_loss: 0.5238 - val_accuracy: 0.8696\n",
            "Epoch 15/20\n",
            "30/30 [==============================] - 1s 40ms/step - loss: 0.0211 - accuracy: 0.9947 - val_loss: 0.5483 - val_accuracy: 0.8710\n",
            "Epoch 16/20\n",
            "30/30 [==============================] - 1s 38ms/step - loss: 0.0196 - accuracy: 0.9953 - val_loss: 0.5896 - val_accuracy: 0.8661\n",
            "Epoch 17/20\n",
            "30/30 [==============================] - 1s 40ms/step - loss: 0.0080 - accuracy: 0.9996 - val_loss: 0.6192 - val_accuracy: 0.8642\n",
            "Epoch 18/20\n",
            "30/30 [==============================] - 1s 37ms/step - loss: 0.0137 - accuracy: 0.9970 - val_loss: 0.6458 - val_accuracy: 0.8669\n",
            "Epoch 19/20\n",
            "30/30 [==============================] - 1s 38ms/step - loss: 0.0050 - accuracy: 0.9999 - val_loss: 0.6889 - val_accuracy: 0.8619\n",
            "Epoch 20/20\n",
            "30/30 [==============================] - 1s 37ms/step - loss: 0.0098 - accuracy: 0.9982 - val_loss: 0.7098 - val_accuracy: 0.8653\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fab93f37b50>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluation\n",
        "results = model.evaluate(x_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WiWnlcOsI8E8",
        "outputId": "06e44573-b79d-4528-e559-a1b8058fbf23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 2s 3ms/step - loss: 0.7800 - accuracy: 0.8490\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from prettytable import PrettyTable\n",
        "#Prediction\n",
        "preds = model.predict(x_test [0:10])\n",
        "\n",
        "t = PrettyTable(['Real', 'Predicted'])\n",
        "for i, pred in enumerate(preds):\n",
        "    t.add_row([y_test [i], round(preds [i,0],2)])\n",
        "print(t)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YjDJBhXNJF-8",
        "outputId": "7ee91b3a-39f2-49ee-ac19-bdf239be85a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----------+\n",
            "| Real | Predicted |\n",
            "+------+-----------+\n",
            "| 0.0  |    0.01   |\n",
            "| 1.0  |    1.0    |\n",
            "| 1.0  |    0.9    |\n",
            "| 0.0  |    0.98   |\n",
            "| 1.0  |    1.0    |\n",
            "| 1.0  |    1.0    |\n",
            "| 1.0  |    0.98   |\n",
            "| 0.0  |    0.0    |\n",
            "| 0.0  |    0.99   |\n",
            "| 1.0  |    1.0    |\n",
            "+------+-----------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets import imdb\n",
        "from keras.preprocessing import sequence\n",
        "\n",
        "max_features = 10000\n",
        "maxlen = 500\n",
        "batch_size = 32\n",
        "\n",
        "#Load data and pad it\n",
        "(input_train, y_train), (input_test, y_test) = imdb.load_data(num_words=max_features)\n",
        "input_train = sequence.pad_sequences(input_train, maxlen=maxlen)\n",
        "input_test = sequence.pad_sequences(input_test, maxlen=maxlen)"
      ],
      "metadata": {
        "id": "o3K-t8YeJISU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Embedding, SimpleRNN, Dense\n",
        "\n",
        "#Define model\n",
        "model = models.Sequential()\n",
        "model.add(Embedding(max_features, 32))\n",
        "model.add(SimpleRNN(32))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='rmsprop', \n",
        "              loss='binary_crossentropy', \n",
        "              metrics=['acc'])\n",
        "\n",
        "#Train the model\n",
        "model.fit(input_train, y_train,\n",
        "          epochs=15,\n",
        "          batch_size=128,\n",
        "          validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M2vUg_rNLxXh",
        "outputId": "46f18a09-468c-4fe2-a742-7f4676844f44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "157/157 [==============================] - 29s 171ms/step - loss: 0.5698 - acc: 0.6951 - val_loss: 0.4320 - val_acc: 0.8072\n",
            "Epoch 2/15\n",
            "157/157 [==============================] - 29s 185ms/step - loss: 0.3574 - acc: 0.8552 - val_loss: 0.3600 - val_acc: 0.8476\n",
            "Epoch 3/15\n",
            "157/157 [==============================] - 27s 170ms/step - loss: 0.2867 - acc: 0.8888 - val_loss: 0.4511 - val_acc: 0.7912\n",
            "Epoch 4/15\n",
            "157/157 [==============================] - 27s 174ms/step - loss: 0.2186 - acc: 0.9160 - val_loss: 0.3629 - val_acc: 0.8478\n",
            "Epoch 5/15\n",
            "157/157 [==============================] - 26s 167ms/step - loss: 0.1751 - acc: 0.9355 - val_loss: 0.3599 - val_acc: 0.8572\n",
            "Epoch 6/15\n",
            "157/157 [==============================] - 27s 172ms/step - loss: 0.1257 - acc: 0.9546 - val_loss: 0.4007 - val_acc: 0.8584\n",
            "Epoch 7/15\n",
            "157/157 [==============================] - 26s 168ms/step - loss: 0.0947 - acc: 0.9678 - val_loss: 0.7575 - val_acc: 0.7150\n",
            "Epoch 8/15\n",
            "157/157 [==============================] - 27s 171ms/step - loss: 0.0696 - acc: 0.9775 - val_loss: 0.4759 - val_acc: 0.8454\n",
            "Epoch 9/15\n",
            "157/157 [==============================] - 26s 166ms/step - loss: 0.0482 - acc: 0.9855 - val_loss: 0.5735 - val_acc: 0.8312\n",
            "Epoch 10/15\n",
            "157/157 [==============================] - 26s 167ms/step - loss: 0.0364 - acc: 0.9890 - val_loss: 0.5531 - val_acc: 0.8538\n",
            "Epoch 11/15\n",
            "157/157 [==============================] - 26s 166ms/step - loss: 0.0238 - acc: 0.9932 - val_loss: 0.7276 - val_acc: 0.7728\n",
            "Epoch 12/15\n",
            "157/157 [==============================] - 26s 167ms/step - loss: 0.0219 - acc: 0.9931 - val_loss: 0.7210 - val_acc: 0.7918\n",
            "Epoch 13/15\n",
            "157/157 [==============================] - 26s 167ms/step - loss: 0.0169 - acc: 0.9948 - val_loss: 0.7480 - val_acc: 0.8070\n",
            "Epoch 14/15\n",
            "157/157 [==============================] - 27s 170ms/step - loss: 0.0130 - acc: 0.9961 - val_loss: 0.7295 - val_acc: 0.8284\n",
            "Epoch 15/15\n",
            "157/157 [==============================] - 27s 169ms/step - loss: 0.0143 - acc: 0.9965 - val_loss: 0.7937 - val_acc: 0.8036\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fab8b0f7a50>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluation\n",
        "results = model.evaluate(input_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RkHiOipEL09H",
        "outputId": "46edf893-ce8c-49fe-e940-ee73d88acde6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 21s 27ms/step - loss: 0.8259 - acc: 0.7958\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Define model\n",
        "model = models.Sequential()\n",
        "model.add(Embedding(max_features, 32))\n",
        "model.add(SimpleRNN(32, return_sequences=True))\n",
        "model.add(SimpleRNN(32, return_sequences=True))\n",
        "model.add(SimpleRNN(32, return_sequences=True))\n",
        "model.add(SimpleRNN(32))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='rmsprop', \n",
        "              loss='binary_crossentropy', \n",
        "              metrics=['acc'])\n",
        "\n",
        "#Train the model\n",
        "model.fit(input_train, y_train,\n",
        "          epochs=1,\n",
        "          batch_size=128,\n",
        "          validation_split=0.2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fm0dcx4aL8dx",
        "outputId": "3de5e97f-71c4-4eea-80d9-034b6544824e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "157/157 [==============================] - 103s 623ms/step - loss: 0.6636 - acc: 0.5818 - val_loss: 0.4986 - val_acc: 0.7574\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fab8ff75910>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluation\n",
        "results = model.evaluate(input_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sf6f-YYIL9NJ",
        "outputId": "a49374f3-59b8-42d3-85d6-94d709e3e2bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 74s 95ms/step - loss: 0.4929 - acc: 0.7666\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# How to setup a CNN model for imdb sentiment analysis in Keras\n",
        "\n",
        "def Snippet_381(): \n",
        "\n",
        "    print()\n",
        "    print(format('How to setup a CNN model for sentiment analysis in Keras','*^82'))\n",
        "\n",
        "    import time\n",
        "    start_time = time.time()\n",
        "\n",
        "    # load libraries\n",
        "    from keras.datasets import imdb\n",
        "    from keras.models import Sequential\n",
        "    from keras.layers import Dense, Flatten\n",
        "    from keras.layers.convolutional import Conv1D, MaxPooling1D\n",
        "    from keras.layers.embeddings import Embedding\n",
        "    from keras.preprocessing import sequence\n",
        "    \n",
        "    # load data and Set the number of words we want\n",
        "    top_words = 5000\n",
        "    input_length = 500\n",
        "\n",
        "    # Load data and target vector from movie review data\n",
        "    (X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=top_words)\n",
        "    \n",
        "    print(); print(X_train.shape); print(X_train)\n",
        "    print(); print(y_train.shape); print(y_train)    \n",
        "    print(); print(X_test.shape);  print(X_test)\n",
        "    print(); print(y_test.shape);  print(y_test)    \n",
        "    \n",
        "    # Convert movie review data to feature matrix\n",
        "    X_train = sequence.pad_sequences(X_train, maxlen=input_length)\n",
        "    print(); print(X_train.shape); print(X_train)\n",
        "\n",
        "    X_test = sequence.pad_sequences(X_test, maxlen=input_length)\n",
        "    print(); print(X_test.shape);  print(X_test)\n",
        "\n",
        "    # setup a CNN network\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(top_words, 32, input_length=input_length))\n",
        "    model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
        "    model.add(MaxPooling1D(pool_size=2))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(250, activation='relu'))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    model.summary()\n",
        "\n",
        "    # Fit the model\n",
        "    model.fit(X_train, y_train, validation_data=(X_test, y_test), \n",
        "              epochs=20, batch_size=128, verbose=1)\n",
        "\n",
        "    # Final evaluation of the model\n",
        "    scores = model.evaluate(X_test, y_test, verbose=1)\n",
        "\n",
        "    print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n",
        "    print(); print(\"Execution Time %s seconds: \" % (time.time() - start_time))\n",
        "\n",
        "Snippet_381()"
      ],
      "metadata": {
        "id": "7diRdiaBL-3p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1e54efc-5442-4acf-e12f-81c2b01d9e65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "*************How to setup a CNN model for sentiment analysis in Keras*************\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n",
            "17473536/17464789 [==============================] - 0s 0us/step\n",
            "\n",
            "(25000,)\n",
            "[list([1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 2, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 2, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 2, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 2, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 2, 19, 178, 32])\n",
            " list([1, 194, 1153, 194, 2, 78, 228, 5, 6, 1463, 4369, 2, 134, 26, 4, 715, 8, 118, 1634, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 3103, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2300, 1523, 5, 647, 4, 116, 9, 35, 2, 4, 229, 9, 340, 1322, 4, 118, 9, 4, 130, 4901, 19, 4, 1002, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 1543, 1905, 398, 4, 1649, 26, 2, 5, 163, 11, 3215, 2, 4, 1153, 9, 194, 775, 7, 2, 2, 349, 2637, 148, 605, 2, 2, 15, 123, 125, 68, 2, 2, 15, 349, 165, 4362, 98, 5, 4, 228, 9, 43, 2, 1157, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 4373, 228, 2, 5, 2, 656, 245, 2350, 5, 4, 2, 131, 152, 491, 18, 2, 32, 2, 1212, 14, 9, 6, 371, 78, 22, 625, 64, 1382, 9, 8, 168, 145, 23, 4, 1690, 15, 16, 4, 1355, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95])\n",
            " list([1, 14, 47, 8, 30, 31, 7, 4, 249, 108, 7, 4, 2, 54, 61, 369, 13, 71, 149, 14, 22, 112, 4, 2401, 311, 12, 16, 3711, 33, 75, 43, 1829, 296, 4, 86, 320, 35, 534, 19, 263, 4821, 1301, 4, 1873, 33, 89, 78, 12, 66, 16, 4, 360, 7, 4, 58, 316, 334, 11, 4, 1716, 43, 645, 662, 8, 257, 85, 1200, 42, 1228, 2578, 83, 68, 3912, 15, 36, 165, 1539, 278, 36, 69, 2, 780, 8, 106, 14, 2, 1338, 18, 6, 22, 12, 215, 28, 610, 40, 6, 87, 326, 23, 2300, 21, 23, 22, 12, 272, 40, 57, 31, 11, 4, 22, 47, 6, 2307, 51, 9, 170, 23, 595, 116, 595, 1352, 13, 191, 79, 638, 89, 2, 14, 9, 8, 106, 607, 624, 35, 534, 6, 227, 7, 129, 113])\n",
            " ...\n",
            " list([1, 11, 6, 230, 245, 2, 9, 6, 1225, 446, 2, 45, 2174, 84, 2, 4007, 21, 4, 912, 84, 2, 325, 725, 134, 2, 1715, 84, 5, 36, 28, 57, 1099, 21, 8, 140, 8, 703, 5, 2, 84, 56, 18, 1644, 14, 9, 31, 7, 4, 2, 1209, 2295, 2, 1008, 18, 6, 20, 207, 110, 563, 12, 8, 2901, 2, 8, 97, 6, 20, 53, 4767, 74, 4, 460, 364, 1273, 29, 270, 11, 960, 108, 45, 40, 29, 2961, 395, 11, 6, 4065, 500, 7, 2, 89, 364, 70, 29, 140, 4, 64, 4780, 11, 4, 2678, 26, 178, 4, 529, 443, 2, 5, 27, 710, 117, 2, 2, 165, 47, 84, 37, 131, 818, 14, 595, 10, 10, 61, 1242, 1209, 10, 10, 288, 2260, 1702, 34, 2901, 2, 4, 65, 496, 4, 231, 7, 790, 5, 6, 320, 234, 2766, 234, 1119, 1574, 7, 496, 4, 139, 929, 2901, 2, 2, 5, 4241, 18, 4, 2, 2, 250, 11, 1818, 2, 4, 4217, 2, 747, 1115, 372, 1890, 1006, 541, 2, 7, 4, 59, 2, 4, 3586, 2])\n",
            " list([1, 1446, 2, 69, 72, 3305, 13, 610, 930, 8, 12, 582, 23, 5, 16, 484, 685, 54, 349, 11, 4120, 2959, 45, 58, 1466, 13, 197, 12, 16, 43, 23, 2, 5, 62, 30, 145, 402, 11, 4131, 51, 575, 32, 61, 369, 71, 66, 770, 12, 1054, 75, 100, 2198, 8, 4, 105, 37, 69, 147, 712, 75, 3543, 44, 257, 390, 5, 69, 263, 514, 105, 50, 286, 1814, 23, 4, 123, 13, 161, 40, 5, 421, 4, 116, 16, 897, 13, 2, 40, 319, 2, 112, 2, 11, 4803, 121, 25, 70, 3468, 4, 719, 3798, 13, 18, 31, 62, 40, 8, 2, 4, 2, 7, 14, 123, 5, 942, 25, 8, 721, 12, 145, 5, 202, 12, 160, 580, 202, 12, 6, 52, 58, 2, 92, 401, 728, 12, 39, 14, 251, 8, 15, 251, 5, 2, 12, 38, 84, 80, 124, 12, 9, 23])\n",
            " list([1, 17, 6, 194, 337, 7, 4, 204, 22, 45, 254, 8, 106, 14, 123, 4, 2, 270, 2, 5, 2, 2, 732, 2098, 101, 405, 39, 14, 1034, 4, 1310, 9, 115, 50, 305, 12, 47, 4, 168, 5, 235, 7, 38, 111, 699, 102, 7, 4, 4039, 2, 9, 24, 6, 78, 1099, 17, 2345, 2, 21, 27, 2, 2, 5, 2, 1603, 92, 1183, 4, 1310, 7, 4, 204, 42, 97, 90, 35, 221, 109, 29, 127, 27, 118, 8, 97, 12, 157, 21, 2, 2, 9, 6, 66, 78, 1099, 4, 631, 1191, 5, 2642, 272, 191, 1070, 6, 2, 8, 2197, 2, 2, 544, 5, 383, 1271, 848, 1468, 2, 497, 2, 8, 1597, 2, 2, 21, 60, 27, 239, 9, 43, 2, 209, 405, 10, 10, 12, 764, 40, 4, 248, 20, 12, 16, 5, 174, 1791, 72, 7, 51, 6, 1739, 22, 4, 204, 131, 9])]\n",
            "\n",
            "(25000,)\n",
            "[1 0 0 ... 0 1 0]\n",
            "\n",
            "(25000,)\n",
            "[list([1, 591, 202, 14, 31, 6, 717, 10, 10, 2, 2, 5, 4, 360, 7, 4, 177, 2, 394, 354, 4, 123, 9, 1035, 1035, 1035, 10, 10, 13, 92, 124, 89, 488, 2, 100, 28, 1668, 14, 31, 23, 27, 2, 29, 220, 468, 8, 124, 14, 286, 170, 8, 157, 46, 5, 27, 239, 16, 179, 2, 38, 32, 25, 2, 451, 202, 14, 6, 717])\n",
            " list([1, 14, 22, 3443, 6, 176, 7, 2, 88, 12, 2679, 23, 1310, 5, 109, 943, 4, 114, 9, 55, 606, 5, 111, 7, 4, 139, 193, 273, 23, 4, 172, 270, 11, 2, 2, 4, 2, 2801, 109, 1603, 21, 4, 22, 3861, 8, 6, 1193, 1330, 10, 10, 4, 105, 987, 35, 841, 2, 19, 861, 1074, 5, 1987, 2, 45, 55, 221, 15, 670, 2, 526, 14, 1069, 4, 405, 5, 2438, 7, 27, 85, 108, 131, 4, 2, 2, 3884, 405, 9, 3523, 133, 5, 50, 13, 104, 51, 66, 166, 14, 22, 157, 9, 4, 530, 239, 34, 2, 2801, 45, 407, 31, 7, 41, 3778, 105, 21, 59, 299, 12, 38, 950, 5, 4521, 15, 45, 629, 488, 2733, 127, 6, 52, 292, 17, 4, 2, 185, 132, 1988, 2, 1799, 488, 2693, 47, 6, 392, 173, 4, 2, 4378, 270, 2352, 4, 1500, 7, 4, 65, 55, 73, 11, 346, 14, 20, 9, 6, 976, 2078, 7, 2, 861, 2, 5, 4182, 30, 3127, 2, 56, 4, 841, 5, 990, 692, 8, 4, 1669, 398, 229, 10, 10, 13, 2822, 670, 2, 14, 9, 31, 7, 27, 111, 108, 15, 2033, 19, 2, 1429, 875, 551, 14, 22, 9, 1193, 21, 45, 4829, 5, 45, 252, 8, 2, 6, 565, 921, 3639, 39, 4, 529, 48, 25, 181, 8, 67, 35, 1732, 22, 49, 238, 60, 135, 1162, 14, 9, 290, 4, 58, 10, 10, 472, 45, 55, 878, 8, 169, 11, 374, 2, 25, 203, 28, 8, 818, 12, 125, 4, 3077])\n",
            " list([1, 111, 748, 4368, 1133, 2, 2, 4, 87, 1551, 1262, 7, 31, 318, 2, 7, 4, 498, 2, 748, 63, 29, 2, 220, 686, 2, 5, 17, 12, 575, 220, 2507, 17, 6, 185, 132, 2, 16, 53, 928, 11, 2, 74, 4, 438, 21, 27, 2, 589, 8, 22, 107, 2, 2, 997, 1638, 8, 35, 2076, 2, 11, 22, 231, 54, 29, 1706, 29, 100, 2, 2425, 34, 2, 2, 2, 5, 2, 98, 31, 2122, 33, 6, 58, 14, 3808, 1638, 8, 4, 365, 7, 2789, 3761, 356, 346, 4, 2, 1060, 63, 29, 93, 11, 2, 11, 2, 33, 6, 58, 54, 1270, 431, 748, 7, 32, 2580, 16, 11, 94, 2, 10, 10, 4, 993, 2, 7, 4, 1766, 2634, 2164, 2, 8, 847, 8, 1450, 121, 31, 7, 27, 86, 2663, 2, 16, 6, 465, 993, 2006, 2, 573, 17, 2, 42, 4, 2, 37, 473, 6, 711, 6, 2, 7, 328, 212, 70, 30, 258, 11, 220, 32, 7, 108, 21, 133, 12, 9, 55, 465, 849, 3711, 53, 33, 2071, 1969, 37, 70, 1144, 4, 2, 1409, 74, 476, 37, 62, 91, 1329, 169, 4, 1330, 2, 146, 655, 2212, 5, 258, 12, 184, 2, 546, 5, 849, 2, 7, 4, 22, 1436, 18, 631, 1386, 797, 7, 4, 2, 71, 348, 425, 4320, 1061, 19, 2, 5, 2, 11, 661, 8, 339, 2, 4, 2455, 2, 7, 4, 1962, 10, 10, 263, 787, 9, 270, 11, 6, 2, 4, 2, 2, 121, 4, 2, 26, 4434, 19, 68, 1372, 5, 28, 446, 6, 318, 2, 8, 67, 51, 36, 70, 81, 8, 4392, 2294, 36, 1197, 8, 2, 2, 18, 6, 711, 4, 2, 26, 2, 1125, 11, 14, 636, 720, 12, 426, 28, 77, 776, 8, 97, 38, 111, 2, 2, 168, 1239, 2, 137, 2, 18, 27, 173, 9, 2399, 17, 6, 2, 428, 2, 232, 11, 4, 2, 37, 272, 40, 2708, 247, 30, 656, 6, 2, 54, 2, 3292, 98, 6, 2840, 40, 558, 37, 2, 98, 4, 2, 1197, 15, 14, 9, 57, 4893, 5, 4659, 6, 275, 711, 2, 2, 3292, 98, 6, 2, 10, 10, 2, 19, 14, 2, 267, 162, 711, 37, 2, 752, 98, 4, 2, 2378, 90, 19, 6, 2, 7, 2, 1810, 2, 4, 4770, 3183, 930, 8, 508, 90, 4, 1317, 8, 4, 2, 17, 2, 3965, 1853, 4, 1494, 8, 4468, 189, 4, 2, 2, 2, 4, 4770, 5, 95, 271, 23, 6, 2, 2, 2, 2, 33, 1526, 6, 425, 3155, 2, 4535, 1636, 7, 4, 4669, 2, 469, 4, 4552, 54, 4, 150, 2, 2, 280, 53, 2, 2, 18, 339, 29, 1978, 27, 2, 5, 2, 68, 1830, 19, 2, 2, 4, 1515, 7, 263, 65, 2132, 34, 6, 2, 2, 43, 159, 29, 9, 4706, 9, 387, 73, 195, 584, 10, 10, 1069, 4, 58, 810, 54, 14, 2, 117, 22, 16, 93, 5, 1069, 4, 192, 15, 12, 16, 93, 34, 6, 1766, 2, 33, 4, 2, 7, 15, 2, 2, 3286, 325, 12, 62, 30, 776, 8, 67, 14, 17, 6, 2, 44, 148, 687, 2, 203, 42, 203, 24, 28, 69, 2, 2, 11, 330, 54, 29, 93, 2, 21, 845, 2, 27, 1099, 7, 819, 4, 22, 1407, 17, 6, 2, 787, 7, 2460, 2, 2, 100, 30, 4, 3737, 3617, 3169, 2321, 42, 1898, 11, 4, 3814, 42, 101, 704, 7, 101, 999, 15, 1625, 94, 2926, 180, 5, 9, 2, 34, 2, 45, 6, 1429, 22, 60, 6, 1220, 31, 11, 94, 2, 96, 21, 94, 749, 9, 57, 975])\n",
            " ...\n",
            " list([1, 13, 1408, 15, 8, 135, 14, 9, 35, 32, 46, 394, 20, 62, 30, 2, 21, 45, 184, 78, 4, 1492, 910, 769, 2290, 2515, 395, 4257, 5, 1454, 11, 119, 2, 89, 1036, 4, 116, 218, 78, 21, 407, 100, 30, 128, 262, 15, 7, 185, 2280, 284, 1842, 2, 37, 315, 4, 226, 20, 272, 2942, 40, 29, 152, 60, 181, 8, 30, 50, 553, 362, 80, 119, 12, 21, 846, 2])\n",
            " list([1, 11, 119, 241, 9, 4, 840, 20, 12, 468, 15, 94, 3684, 562, 791, 39, 4, 86, 107, 8, 97, 14, 31, 33, 4, 2960, 7, 743, 46, 1028, 9, 3531, 5, 4, 768, 47, 8, 79, 90, 145, 164, 162, 50, 6, 501, 119, 7, 9, 4, 78, 232, 15, 16, 224, 11, 4, 333, 20, 4, 985, 200, 5, 2, 5, 9, 1861, 8, 79, 357, 4, 20, 47, 220, 57, 206, 139, 11, 12, 5, 55, 117, 212, 13, 1276, 92, 124, 51, 45, 1188, 71, 536, 13, 520, 14, 20, 6, 2302, 7, 470])\n",
            " list([1, 6, 52, 2, 430, 22, 9, 220, 2594, 8, 28, 2, 519, 3227, 6, 769, 15, 47, 6, 3482, 4067, 8, 114, 5, 33, 222, 31, 55, 184, 704, 2, 2, 19, 346, 3153, 5, 6, 364, 350, 4, 184, 2, 9, 133, 1810, 11, 2, 2, 21, 4, 2, 2, 570, 50, 2005, 2643, 9, 6, 1249, 17, 6, 2, 2, 21, 17, 6, 1211, 232, 1138, 2249, 29, 266, 56, 96, 346, 194, 308, 9, 194, 21, 29, 218, 1078, 19, 4, 78, 173, 7, 27, 2, 2, 3406, 718, 2, 9, 6, 2, 17, 210, 5, 3281, 2, 47, 77, 395, 14, 172, 173, 18, 2740, 2931, 4517, 82, 127, 27, 173, 11, 6, 392, 217, 21, 50, 9, 57, 65, 12, 2, 53, 40, 35, 390, 7, 11, 4, 3567, 7, 4, 314, 74, 6, 792, 22, 2, 19, 714, 727, 2, 382, 4, 91, 2, 439, 19, 14, 20, 9, 1441, 2, 1118, 4, 756, 25, 124, 4, 31, 12, 16, 93, 804, 34, 2005, 2643])]\n",
            "\n",
            "(25000,)\n",
            "[0 1 1 ... 0 0 0]\n",
            "\n",
            "(25000, 500)\n",
            "[[   0    0    0 ...   19  178   32]\n",
            " [   0    0    0 ...   16  145   95]\n",
            " [   0    0    0 ...    7  129  113]\n",
            " ...\n",
            " [   0    0    0 ...    4 3586    2]\n",
            " [   0    0    0 ...   12    9   23]\n",
            " [   0    0    0 ...  204  131    9]]\n",
            "\n",
            "(25000, 500)\n",
            "[[   0    0    0 ...   14    6  717]\n",
            " [   0    0    0 ...  125    4 3077]\n",
            " [  33    6   58 ...    9   57  975]\n",
            " ...\n",
            " [   0    0    0 ...   21  846    2]\n",
            " [   0    0    0 ... 2302    7  470]\n",
            " [   0    0    0 ...   34 2005 2643]]\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 500, 32)           160000    \n",
            "                                                                 \n",
            " conv1d (Conv1D)             (None, 500, 32)           3104      \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1D  (None, 250, 32)          0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 8000)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 250)               2000250   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 251       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,163,605\n",
            "Trainable params: 2,163,605\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "196/196 [==============================] - 32s 158ms/step - loss: 0.4396 - accuracy: 0.7739 - val_loss: 0.2782 - val_accuracy: 0.8837\n",
            "Epoch 2/20\n",
            "196/196 [==============================] - 31s 156ms/step - loss: 0.2149 - accuracy: 0.9160 - val_loss: 0.2875 - val_accuracy: 0.8784\n",
            "Epoch 3/20\n",
            "196/196 [==============================] - 32s 163ms/step - loss: 0.1568 - accuracy: 0.9409 - val_loss: 0.2983 - val_accuracy: 0.8822\n",
            "Epoch 4/20\n",
            "196/196 [==============================] - 32s 161ms/step - loss: 0.1032 - accuracy: 0.9662 - val_loss: 0.3404 - val_accuracy: 0.8760\n",
            "Epoch 5/20\n",
            "196/196 [==============================] - 32s 161ms/step - loss: 0.0522 - accuracy: 0.9863 - val_loss: 0.4292 - val_accuracy: 0.8692\n",
            "Epoch 6/20\n",
            "196/196 [==============================] - 31s 160ms/step - loss: 0.0205 - accuracy: 0.9967 - val_loss: 0.4896 - val_accuracy: 0.8714\n",
            "Epoch 7/20\n",
            "196/196 [==============================] - 31s 157ms/step - loss: 0.0067 - accuracy: 0.9993 - val_loss: 0.5830 - val_accuracy: 0.8719\n",
            "Epoch 8/20\n",
            "196/196 [==============================] - 31s 160ms/step - loss: 0.0021 - accuracy: 0.9998 - val_loss: 0.6455 - val_accuracy: 0.8712\n",
            "Epoch 9/20\n",
            "196/196 [==============================] - 31s 157ms/step - loss: 9.8180e-04 - accuracy: 0.9999 - val_loss: 0.6968 - val_accuracy: 0.8720\n",
            "Epoch 10/20\n",
            "196/196 [==============================] - 31s 158ms/step - loss: 4.8171e-04 - accuracy: 1.0000 - val_loss: 0.7442 - val_accuracy: 0.8723\n",
            "Epoch 11/20\n",
            "196/196 [==============================] - 31s 160ms/step - loss: 3.0118e-04 - accuracy: 1.0000 - val_loss: 0.7895 - val_accuracy: 0.8728\n",
            "Epoch 12/20\n",
            "196/196 [==============================] - 31s 160ms/step - loss: 1.9043e-04 - accuracy: 1.0000 - val_loss: 0.8372 - val_accuracy: 0.8720\n",
            "Epoch 13/20\n",
            "196/196 [==============================] - 31s 159ms/step - loss: 1.2273e-04 - accuracy: 1.0000 - val_loss: 0.8837 - val_accuracy: 0.8730\n",
            "Epoch 14/20\n",
            "196/196 [==============================] - 31s 157ms/step - loss: 7.9370e-05 - accuracy: 1.0000 - val_loss: 0.9254 - val_accuracy: 0.8728\n",
            "Epoch 15/20\n",
            "196/196 [==============================] - 32s 163ms/step - loss: 5.3272e-05 - accuracy: 1.0000 - val_loss: 0.9685 - val_accuracy: 0.8731\n",
            "Epoch 16/20\n",
            "196/196 [==============================] - 32s 161ms/step - loss: 3.7292e-05 - accuracy: 1.0000 - val_loss: 1.0059 - val_accuracy: 0.8728\n",
            "Epoch 17/20\n",
            "196/196 [==============================] - 31s 159ms/step - loss: 2.6770e-05 - accuracy: 1.0000 - val_loss: 1.0374 - val_accuracy: 0.8733\n",
            "Epoch 18/20\n",
            "196/196 [==============================] - 31s 159ms/step - loss: 1.9779e-05 - accuracy: 1.0000 - val_loss: 1.0677 - val_accuracy: 0.8730\n",
            "Epoch 19/20\n",
            "196/196 [==============================] - 31s 160ms/step - loss: 1.5205e-05 - accuracy: 1.0000 - val_loss: 1.0942 - val_accuracy: 0.8733\n",
            "Epoch 20/20\n",
            "196/196 [==============================] - 31s 159ms/step - loss: 1.1867e-05 - accuracy: 1.0000 - val_loss: 1.1207 - val_accuracy: 0.8726\n",
            "782/782 [==============================] - 9s 12ms/step - loss: 1.1207 - accuracy: 0.8726\n",
            "Accuracy: 87.26%\n",
            "\n",
            "Execution Time 709.0914351940155 seconds: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "1PBxbv4yqJGT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}